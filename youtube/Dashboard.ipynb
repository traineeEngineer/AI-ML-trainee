{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51251303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import *\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import fasttext\n",
    "import re\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "model=load_model('model.h5')\n",
    "\n",
    "en_model=fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "model=T5ForConditionalGeneration.from_pretrained('./finetune-t5')\n",
    "tokenizer=T5Tokenizer.from_pretrained('t5-base')\n",
    "prediction_occurrences = {}\n",
    "\n",
    "app=Flask(__name__,template_folder='templates')\n",
    "\n",
    "\n",
    "# preprocess text\n",
    "def preprocess(text):\n",
    "    process_text=re.compile('[^A-Za-z0-9]')\n",
    "    text=re.sub(process_text,' ',text.lower())\n",
    "    return text\n",
    "\n",
    "# convert text into vectors using Fasttext\n",
    "def vectorize_text(text):\n",
    "    vector = en_model.get_sentence_vector(text)\n",
    "    vector = np.reshape(vector, (1, 1, 300))\n",
    "    return vector\n",
    "\n",
    "# generate automated reply for every comment using transformers model\n",
    "def generate_reply(comment):\n",
    "    input_ids=tokenizer.encode(comment,return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output=model.generate(input_ids,\n",
    "                             max_length=256, \n",
    "                             no_repeat_ngram_size=1, \n",
    "                             num_beams=30, \n",
    "                             early_stopping=True,\n",
    "                            )\n",
    "    reply=tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    return reply\n",
    "   \n",
    "@app.route('/')\n",
    "def home(): \n",
    "    return render_template('index.html',prediction_occurrences={})   \n",
    "\n",
    "@app.route('/predict', methods=['GET','POST'])\n",
    "def predict():\n",
    "    \n",
    "    \n",
    "     global prediction_occurrences;\n",
    "    \n",
    "     if request.method == 'POST':\n",
    "        input_text = request.form['text']\n",
    "   \n",
    "        processed_text = preprocess(input_text)\n",
    "\n",
    "        vectorized_text = vectorize_text(processed_text)\n",
    "\n",
    "        prediction = model.predict(vectorized_text)\n",
    "\n",
    "        predicted_class = np.argmax(prediction)\n",
    "\n",
    "        classes = [ 'Gratitude','About the recipe','About the video','Praising','Hybrid','Undefined','Suggestions and queries']\n",
    "        result = classes[predicted_class]\n",
    "        \n",
    "        prediction_occurrences[result] = prediction_occurrences.get(result, 0) + 1\n",
    "        \n",
    "        # automate reply with T5 model if prediction is Gratitude and praising \n",
    "        if result in ['Gratitude','Praising','About the recipe','About the video','Hybrid','Undefined']:\n",
    "            automated_reply=generate_reply(input_text)\n",
    "            \n",
    "            return render_template('index.html', prediction=result, automated_reply=automated_reply,\n",
    "                                   prediction_occurrences=prediction_occurrences)\n",
    "        \n",
    "        return render_template('index.html', prediction=result,prediction_occurrences=prediction_occurrences)\n",
    "          \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True,use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41cbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\n",
    "    'comments':[\n",
    "        'wooooooo its very yummmmmm I love it',\n",
    "        'thanx.. respect from',\n",
    "        'you re amazing',\n",
    "        'thank u so much ...love u  my friend.Im from Dubai',\n",
    "        'u r awesome kabita ji',\n",
    "        'aap mujhe bahut pasand ho mam',\n",
    "        'mast',\n",
    "        'very good',\n",
    "        'i tried it today it came out delicious.. I have added kade masala and other  ingredients 1.5 times more for 2kg chicken and 1 kg 100 gm  basmathi rice and i followed each and every step  it came out really well.. My family loved the recipe.. Thank u for sharing this recipe',\n",
    "        'very nice kabita sis ,I m in Madurai Tamil nadu',\n",
    "        'nice presentation',\n",
    "        'wow nice',\n",
    "        'u r the best chef on youtube mam',\n",
    "        'super recipe mam ....I tried it... It was awesome.... Thanks a lot... super you are Keep going',\n",
    "        'so nice Awesome',\n",
    "        'Kabita mam, you are the only reason i learned cooking. Not only that i made cooking as my hobby, being a bachelor my roommates always wait for me to come from office and make something for them. All the credit goes to you mam, you are really awesome',\n",
    "        'i love you darling',\n",
    "        'wonderful',\n",
    "        'sister aapka video dekhne ke baad mene life me first time biryani banai, aur jab biryani ban gayi toh gharwale ungliya chatate reh gaye, thank you sister',\n",
    "        'hello Kabita Ma am ... Aaj Maine Aapne bataya huye tarike se biryani Banayi... Bahut he acchi Bani thi... Thanks for sharing this recepe with us',\n",
    "        'you are best',\n",
    "        'So easy n delicious i learned frm u only',\n",
    "        'tqqq Didi muja reply daynay ka khaliea.',\n",
    "        'Kabitha mam appki lookg so cuteeeeeee',\n",
    "        'mam aupka language bahut acha lagta hai',\n",
    "        'very nice mam Maine banaya bhut testy Bani thanks',\n",
    "        'you deserve 10M subscribers mam',\n",
    "        'superb',\n",
    "        'you are a gem Much love',\n",
    "        'kabita mam i follow u regularly n ur dishes nvr fail to get me appreciaion from my mother',\n",
    "        'owowwo Nice one mam',\n",
    "        'u r tips r really good',\n",
    "        'i don t like your style',\n",
    "        'gajab ek no ban',\n",
    "        'mashallah Bahut Umda', \n",
    "        'all credit goes to u',   \n",
    "        'mem aap bhut acha Khan bante ho',\n",
    "        'most wonderful and welcome',\n",
    "        'swaad hi aa gya.. mast bni h biryani.. thanku mam',\n",
    "        'u r good as always',\n",
    "        'my god bless your hands thank you mam',\n",
    "        'fantastic good job',\n",
    "        'waah kavita di mjaa aa gya. Hats off to u',\n",
    "        'star***** you are a star in cooking....loyal',\n",
    "        'bhut sundr ha aap',\n",
    "        'bahoot achhi',\n",
    "        'love u a lottttt...may god bless u wdh d entire happiness of dis world',\n",
    "        'ur SWEET mam',\n",
    "        'very helpful.. Thanku mam',\n",
    "        'bahut bahut bahut achha laga',\n",
    "        'i love your innovativ idea',\n",
    "        'dear aunty g You deserve an Oscar for cooking from us',\n",
    "        'mai apki bohot badhi fan hun',\n",
    "        'great dear',\n",
    "        'im ur biggest fan kabita ji.. n my mom also',\n",
    "        'aap k bataney ka tarika bahut acha hey',\n",
    "        'hats off 2 u',\n",
    "        'thanx...its very easy',\n",
    "        'allah ne kya hunar baksha h',\n",
    "        'jb se apke btaye trike se khana bnane lgi hn mere hubby bahr khana hi chhod diye thhhhnxxx didu',\n",
    "        'i love your simple preparation..keep going',\n",
    "        'bohot achha...thank u',\n",
    "        'beautiful',\n",
    "        # 'I dont like it at all',\n",
    "        # 'Jal gaya tha',\n",
    "        # 'Naaam bada darshan chota not satisfied with this recipe lots of mistake',\n",
    "        # 'bakwash',\n",
    "        # 'chiii mene try ki ghr pr  biryani ki naam ki insult h ye plzz guys koi try mt krna ghr pr',\n",
    "        # 'I dont like this biriyani',\n",
    "        # 'Lolllll Yeh biryani Hai ya sabji Ese Todhi na Banti Hai pagal biryani',\n",
    "        # 'badi mushkil h',\n",
    "        # 'thnxc for vidoes.....kavita mam',\n",
    "        # 'I hate it',\n",
    "        # 'I don t like maggi',\n",
    "        # 'Banne ke bad bahut lalach lag raha hai',\n",
    "        # 'Nice video',\n",
    "        # 'Your recipes are always good',\n",
    "        # 'Mujhe video bahot acchalaga',\n",
    "        # 'No one like u',  \n",
    "        # 'Very tasty luv it',  \n",
    "    ],\n",
    "    'reply':[\n",
    "        'im glad to hear you enjoyed it',\n",
    "        'youre welcome! sending respect right back at ya',\n",
    "        'thank you so much! That means a lot to me.',\n",
    "        'youre welcome! sending warm regards back to you',\n",
    "        'thank you for your kind words! I appreciate your encouragement',\n",
    "        'shukriya! aapka yeh izhar bahut khushi ka mauka hai.',\n",
    "        'bilkul koi baat nahi!',\n",
    "        'thank you',\n",
    "        'thats fantastic to hear! im thrilled the recipe turned out so well for you and that your family enjoyed it.',\n",
    "        'thank you so much! Madurai is such a beautiful place',\n",
    "        'i appreciate the compliment.',\n",
    "        'i appreciate it',\n",
    "        'thank you so much, im thrilled to hear that you enjoy my cooking videos',\n",
    "        'your feedback means a lot to me.',\n",
    "        'thank you! im glad you think so.',\n",
    "        'it warms my heart to hear that',\n",
    "        'i love you too, darling. you mean the world to me',\n",
    "        'thank you for your kind words',\n",
    "        'arrey wah, bohot accha hai! biryani banana ek art hai aur tumne pehli baar hi itna achha kiya, mubarak ho! Aur gharwale ki khushi ka koi mukabla nahi',\n",
    "        'hey, thank you! Bahut achha laga sunke ki aapko biryani pasand aayi. Khushi hui ki aapne try kiya aur pasand aaya. Agar koi aur recipe try karna ho toh mujhse share karna mat bhoolna',\n",
    "        'thank you for your kind words',\n",
    "        'thank you!',\n",
    "        'ji zaroor, apka koi sawal hai ya kuch specific janna chahte hain',\n",
    "        'arrey, thank you yaar! tum bhi bilkul cute ho',\n",
    "        'dhanyavad! Mujhe khushi hai ki aapko meri bhasha pasand aayi.',\n",
    "        'thank you! Aapka yeh feedback bahut achha laga',\n",
    "        'i truly appreciate your support and encouragement',\n",
    "        'thank you for the compliment',\n",
    "        'sending much love right back to you',\n",
    "        'im delighted to hear that my recipes have been a hit with you and your mother',\n",
    "        'im glad you liked it',\n",
    "        'im glad you find my tips helpful',\n",
    "        'i appreciate your feedback. is there something specific you d like to see differently, or any suggestions you have in mind',\n",
    "        'arre bhai, bilkul ek no! thanks yaar, tumne dil khush kar diya',\n",
    "        'mashallah, bahut shukriya! aapka pyaar aur sammaan hamesha ke liye yaad rahega',\n",
    "        'i really appreciate your acknowledgment',\n",
    "        'dhanyavaad! Main khana banane mein dil se laga hoon',\n",
    "        'thank you very much!',\n",
    "        'bohot khushi hui ki biryani pasand aayi! aapka swagat hai, anytime',\n",
    "        'thank you! I m here to help whenever you need assistance',\n",
    "        'thank you so much for your kind words! its my pleasure to help',\n",
    "        'your appreciation fuels my dedication',\n",
    "        'shukriya! aapka pyaar aur samman hamesha muskurahat ka saathi banata hai.',\n",
    "        'thank you for the stellar compliment',\n",
    "        'shukriya! Aapka yeh pyara sandesh mere dil ko choo gaya',\n",
    "        'kya baat hai, dil khush kar diya',\n",
    "        'your affection fills my heart with warmth and joy',\n",
    "        'thank you for your kindness',\n",
    "        'youre welcome! glad i could assist',\n",
    "        'yeh sunke mujhe bhi bahut khushi hui',\n",
    "        'your appreciation fuels my passion for innovation even more',\n",
    "        'thank you so much for the heartfelt compliment',\n",
    "        'wow, sach? Yeh toh amazing hai! Dil se shukriya, yaar',\n",
    "        'thanks!',\n",
    "        'im truly grateful to have fans like you and your mom',\n",
    "        'dhanyavaad! aapki tareef sun kar khushi hu',\n",
    "        'thank you! i tip my hat right back at you',\n",
    "        'glad I could make it straightforward for you',\n",
    "        'allah ne mujhe pyaar dena ka khaas hunar baksha hai',\n",
    "        'arrey wah! bahut khushi hui sunke! Ab toh apka ghar ka khana hi sabka dil jeet raha hai na',\n",
    "        'thank you! Ill continue to keep things straightforward and enjoyable',\n",
    "        'bahut shukriya',\n",
    "        'thank you',\n",
    "        # 'I appreciate your honesty. Is there something we can do to make it better for you',\n",
    "        # 'Arre bhai, samajh gaya. Koi baat nahi, agli baar dekhte hain kaise kar sakte hain.',\n",
    "        # 'Understood, we all make the necessary adjustments',\n",
    "        # 'maafi yaar. Next time behtar koshish karenge',\n",
    "        # 'Samajh gaya, shayad kuch gadbad ho gayi hogi. Aage se try nahi karenge, koi baat nahi.',\n",
    "        # 'I understand. We will make sure to improve it next time',\n",
    "        # 'maafi yaar. Lagta hai kuch gadbad ho gayi. Agli baar behtar try karenge',\n",
    "        # 'kuch cheezein thodi mushkil hoti hain. Par hum try karenge aur behtar karenge.',\n",
    "        # 'Youre welcome! Im glad you found the videos helpful',\n",
    "        # 'I understand. Thank you for sharing your honest opinion',\n",
    "        # 'Got it, noted. We ll keep that in mind for future reference',\n",
    "        # 'khane ke baad lalach toh hota hi hai. Par hosh mein raho, control karo',\n",
    "        # 'Thank you! Im glad you enjoyed the video',\n",
    "        # 'Thank you for the compliment! I strive to create unique and delicious recipes',\n",
    "        # 'maza aaya! Agli baar bhi dekhenge.',\n",
    "        # 'Thank you for your feedback. I will strive to improve and hopefully win you over in the future.',\n",
    "        # 'Im glad you enjoyed it! Your appreciation means a lot.'\n",
    "    ]\n",
    "})\n",
    "\n",
    "df=df.to_csv('new_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7525d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d5bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa369bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2796b376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# intialize models\n",
    "MODEL_NAME = 't5-base' #'t5-small'#'t5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f50db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "def pre_process(example):\n",
    "    data={}\n",
    "    data['prompt']=[f\"comments: {comment}\" for comment in example[\"comments\"]]\n",
    "    \n",
    "    data['response']=[f'reply:{reply}' for reply in example['reply']]\n",
    "    \n",
    "    inputs = tokenizer(data['prompt'], padding='max_length', truncation=True, max_length=512)\n",
    "    targets = tokenizer(data['response'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "    inputs.update({'labels': targets[\"input_ids\"]})\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aed87c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c91ce4631844cc84fd596d830fd28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a835cdd1d9945509b37f3a0f14539a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create dataset train and test\n",
    "train_dataset = train_dataset.map(pre_process, batched=True)\n",
    "test_dataset = test_dataset.map(pre_process, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d038f582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea1988bbd5b46f687a2db1010d6e1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./result\\checkpoint-9 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./result\\checkpoint-18 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./result\\checkpoint-27 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./result\\checkpoint-36 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./result\\checkpoint-45 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./result\\checkpoint-54 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./result\\checkpoint-63 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2566.7913, 'train_samples_per_second': 0.136, 'train_steps_per_second': 0.025, 'train_loss': 0.5932701353042845, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=63, training_loss=0.5932701353042845, metrics={'train_runtime': 2566.7913, 'train_samples_per_second': 0.136, 'train_steps_per_second': 0.025, 'train_loss': 0.5932701353042845, 'epoch': 7.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model here\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "TRAINING_OUTPUT = './result' #r\"D:/GenAI/T5/health_samp\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=TRAINING_OUTPUT,\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=6,  # Lower batch size for T5 models\n",
    "    per_device_eval_batch_size=6,   # Lower batch size for T5 models\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=0.001,\n",
    "    save_steps=10000,\n",
    "    max_grad_norm=0.9,\n",
    "    eval_steps=1000,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=test_dataset,  \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36cfe70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "trainer.save_model('./finetune-t5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ad8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model('./finetuned-t5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fb322",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cea1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#initialize fine tuned model\n",
    "model1 = T5ForConditionalGeneration.from_pretrained('./finetune-t5')\n",
    "tokenizer=T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04ae0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generate reply using encoders and decoders\n",
    "def generate_reply(text):\n",
    "    inputs = tokenizer( text, return_tensors='pt', max_length=256, padding='max_length', truncation=True)\n",
    "    outputs = model1.generate(inputs['input_ids'],\n",
    "                             max_length=256, \n",
    "                             no_repeat_ngram_size=1, \n",
    "                             num_beams=30, \n",
    "                             early_stopping=True,\n",
    "                            )\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cc7d74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:your feedback means a lot to me.\n"
     ]
    }
   ],
   "source": [
    "# result for automated reply\n",
    "comment = \"Very tasty luv it\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7166622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:bahut shukriya! You mean the world to me\n"
     ]
    }
   ],
   "source": [
    "comment = \"Aapka beta bahut cute h love you beta\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f58ae9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:thank you for your kind words\n"
     ]
    }
   ],
   "source": [
    "comment = \"Wao mam thanks Mene banae ye recipe...it's so yamm\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe78430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:your appreciation means a lot to me.\n"
     ]
    }
   ],
   "source": [
    "comment = \"super excited thanku\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af5dcabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:bahut shukriya\n"
     ]
    }
   ],
   "source": [
    "comment = \"Boht badiya mam thanks\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4247eece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:thank you so much! I appreciate your encouragement\n"
     ]
    }
   ],
   "source": [
    "comment = \"You're amazing\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4348e98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:arrey, thank you so much! Apki raha hai.\n"
     ]
    }
   ],
   "source": [
    "comment = \"Ap boht achi hain our apki recipe bhi kamal  ki hai\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "294530b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:your feedback means a lot to me.\n"
     ]
    }
   ],
   "source": [
    "comment = \"Your cooking is so neat and clean\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd6c470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Reply: reply:youre welcome! glad you liked it\n"
     ]
    }
   ],
   "source": [
    "comment = \"i like your style\" \n",
    "reply = generate_reply(comment)\n",
    "\n",
    "print(\"Generated Reply:\", reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b18c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2aebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = test_dataset['comments']\n",
    "oup = test_dataset['reply']\n",
    "\n",
    "inp[7],oup[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c113b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_reply(oup[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_reply('Tqqq Didi muja reply daynay ka khaliea'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4bc9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea90c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774755f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba489c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cd569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717126d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debf408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb4dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388ded0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4c6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0884c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4526bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
