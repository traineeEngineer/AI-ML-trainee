{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4073d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "import os\n",
    "\n",
    "llm=LLM(\n",
    "    model='deepseek-r1-distill-llama-70b',\n",
    "    temperature=0.1,\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b466c3f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce49ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent,Task,Crew\n",
    "from crewai_tools import FileReadTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07807bc",
   "metadata": {},
   "source": [
    "# Custom and Crew AI tool function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_reader=FileReadTool('./data/customers.csv')\n",
    "\n",
    "\n",
    "class DataValidatorTool:\n",
    "    def run(self,dataframe):\n",
    "        report=[]\n",
    "        for file_name,df in dataframe.items():\n",
    "            summary={\n",
    "                \"file\":file_name,\n",
    "                \"rows\":len(df),\n",
    "                \"columns\":len(df.columns),\n",
    "                \"null_count\":int(df.isnull().sum().sum()),\n",
    "                \"duplicate_count\":int(df.duplicated().sum())\n",
    "            }\n",
    "            \n",
    "            report.append(summary)\n",
    "        return report\n",
    "    \n",
    "class DataCleanerTool:\n",
    "    def run(self,dataframe_dict):\n",
    "        cleaned_data = {}\n",
    "        report = []\n",
    "\n",
    "        for filename, df in dataframe_dict.items():\n",
    "            cleaned_df = df.dropna().drop_duplicates()\n",
    "\n",
    "            summary = {\n",
    "                \"file\": filename,\n",
    "                \"original_rows\": len(df),\n",
    "                \"rows_after_cleaning\": len(cleaned_df),\n",
    "                \"nulls_removed\": int(df.isnull().sum().sum()),\n",
    "                \"duplicates_removed\": int(df.duplicated().sum())\n",
    "            }\n",
    "\n",
    "            # store cleaned data for further processing\n",
    "            cleaned_data[filename] = cleaned_df\n",
    "            report.append(summary)\n",
    "\n",
    "        return {\"cleaned_data\": cleaned_data, \"report\": report}\n",
    "\n",
    "validator_tool=DataValidatorTool()    \n",
    "cleaner_tool= DataCleanerTool()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2c71b",
   "metadata": {},
   "source": [
    "# Agents Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_agent=Agent(\n",
    "    role=\"Data Loader\",\n",
    "    goal=\"Read local CSV/JSON files prepare for Validation\",\n",
    "    backstory=\"\"\" This agent can scan the local directory ,finds the CSV/JSON files \n",
    "                   and read them into dataframe, and collects metadata for validation\"\"\",\n",
    "    tools=[file_reader],\n",
    "    verbose=True,\n",
    "    llm=llm \n",
    ")\n",
    "\n",
    "validator_agent=Agent(\n",
    "    role =\"Data validator\",\n",
    "    goal=\"Check dataset for missing values,duplicates, and Anomolies\",\n",
    "    backstory=\"\"\"This Agent recieves Dataframes from the loader and runs quality checks so that \n",
    "    the clean ,reliable data can be stored or processe further.\"\"\",\n",
    "    tool=[validator_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "cleaner_agent=Agent(\n",
    "    role=\"Data Cleaner\",\n",
    "    goal=\"Clean dataset any missing values, Duplicate values and Anomolies\",\n",
    "    backstory=\"\"\"This Agent recievs Dataframe from Validator and runs quality check the clean ,reliable data can be stored or processe further.\"\"\",\n",
    "    tool=[cleaner_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2470c68d",
   "metadata": {},
   "source": [
    "# Tasks Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5203c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_task=Task(\n",
    "    description=(\n",
    "        \"1.Scan the 'data/' folder for .csv.\\n\"\n",
    "        \"2.For each file,read it contents into a Pandas Dataframe.\\n\"\n",
    "        \"3.Collect metadata: file name,size,number of rows and columns\\n\"\n",
    "        \"4.Pass DataFrames to the next agent for validation\"\n",
    "        ),\n",
    "    agent=loader_agent,\n",
    "    expected_output=\"A dictionary of file names mapped to Pandas DataFrames for validation.\"\n",
    ")\n",
    "\n",
    "validate_task=Task(\n",
    "    description=(\n",
    "        \"Run data qualit,y check on provided Dataframes.\\n\"\n",
    "        \"1.Count total number of rows\"\n",
    "        \"2.Count Missing values (NAN).\\n\"\n",
    "        \"3.Count duplicate Rows \\n\"\n",
    "        \"Return Summary report for each file\"\n",
    "    ),\n",
    "    agent=validator_agent,\n",
    "    expected_output=\"A JSON report containing file name, rows, columns, null_count, and duplicate_count for each dataset.\"\n",
    ")\n",
    "\n",
    "cleaner_task=Task(\n",
    "    description=(\n",
    "        \"Receive validated DataFrames and clean them by:\\n\"\n",
    "        \"1. Removing all rows with null or NaN values.\\n\"\n",
    "        \"2. Removing all duplicate rows.\\n\"\n",
    "        \"3. Returning both the cleaned DataFrames and a summary report \"\n",
    "        \"showing how many nulls and duplicates were removed for each file.\"\n",
    "        ),\n",
    "    agent=cleaner_agent,\n",
    "    expected_output=(\n",
    "        \"A JSON object containing:\\n\"\n",
    "        \"- 'cleaned_data': dictionary with filenames as keys and cleaned DataFrames as values.\\n\"\n",
    "        \"- 'report': list of summaries for each file, where each summary contains:\\n\"\n",
    "        \"  * file name\\n\"\n",
    "        \"  * original row count\\n\"\n",
    "        \"  * rows after cleaning\\n\"\n",
    "        \"  * nulls removed\\n\"\n",
    "        \"  * duplicates removed\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafb807",
   "metadata": {},
   "source": [
    "# Crew AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b88ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew=Crew(\n",
    "    agents=[loader_agent,validator_agent,cleaner_agent],\n",
    "    tasks=[load_task,validate_task,cleaner_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "res=crew.kickoff()\n",
    "print(\"\\n=== Data Validation Report ===\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26fc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9533c89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabeea36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06bb564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830afd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0978e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640565d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f381a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e76970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ca40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc1827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5156968c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b942a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce859f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e92b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff82a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a99ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e2872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909d0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204c437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c1743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
